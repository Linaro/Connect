---
amazon_s3_presentation_url: None
amazon_s3_video_url: None
author: connect
categories:
- yvr18
comments: false
date: '2018-09-16 09:00:00+00:00'
image:
  featured: true
  name: YVR18-332.png
  path: /assets/images/featured-images/YVR18-332.png
layout: resource-post
session_id: YVR18-332
session_track: 'Machine Learning/AI, AI and Neural Networks on Arm Summit '
slideshare_presentation_url: None
speakers:
- biography: '""'
  company: Linaro BU China
  job-title: Solution Director
  name: Jammy Zhou
  speaker-image: JammyZhou.jpg
title: "YVR18-332: TVM compiler stack and ONNX support"
youtube_video_url: None
---

As an open source deep learning compiler driven by the community, TVM is evolving quickly and well received by the industry. In this session, the architecture of the TVM stack will be introduced first, including some important features added recently such as AutoTVM and VTA (Versatile Tensor Accelerator) support. Then the build and deployment of deep learning models with TVM will be talked about, and ONNX (Open Neural Network eXchange format) is one of the model formats supported by TVM stack. Besides unified model format and operator definitions, ONNXIFI (ONNX Interface for Framework Integration) is another initiative from the ONNX community to define a cross-platform API, and how to fit TVM stack into ONNXIFI seems an interesting topic to discuss as well.