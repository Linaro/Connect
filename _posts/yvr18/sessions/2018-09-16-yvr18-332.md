---
amazon_s3_presentation_url: None
amazon_s3_video_url: https://s3.amazonaws.com/connect.linaro.org/yvr18/videos/yvr18-332.mp4
author: connect
categories:
- yvr18
comments: true
date: '2018-09-16 09:00:00+00:00'
image_name: YVR18-332.png
image: /assets/images/featured-images/YVR18-332.png
layout: resource-post
session_id: YVR18-332
session_track: 'AI/ML, AI and Neural Networks on Arm Summit '
slideshare_presentation_url: None
speakers:
- biography: '""'
  company: Linaro BU China
  job-title: Solution Director
  name: Jammy Zhou
  speaker-image: JammyZhou.jpg
title: "YVR18-332: TVM compiler stack and ONNX support"
youtube_video_url: https://www.youtube.com/watch?v=daYr4tpncFo
tag: session
---

As an open source deep learning compiler driven by the community, TVM is evolving quickly and well received by the industry. In this session, the architecture of the TVM stack will be introduced first, including some important features added recently such as AutoTVM and VTA (Versatile Tensor Accelerator) support. Then the build and deployment of deep learning models with TVM will be talked about, and ONNX (Open Neural Network eXchange format) is one of the model formats supported by TVM stack. Besides unified model format and operator definitions, ONNXIFI (ONNX Interface for Framework Integration) is another initiative from the ONNX community to define a cross-platform API, and how to fit TVM stack into ONNXIFI seems an interesting topic to discuss as well.
