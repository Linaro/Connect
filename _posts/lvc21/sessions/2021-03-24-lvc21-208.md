---
amazon_s3_presentation_url: https://static.linaro.org/connect/lvc21/videos/lvc21-208.mp4
amazon_s3_video_url: https://static.linaro.org/connect/lvc21/presentations/lvc21-208.pdf
categories:
- lvc21
description: "Solid-state storage media is in the process of taking over the data
  center, whose growing advantages in performance bring a major challenge that current
  storage software stack overhead becomes a major bottleneck for developing high performance
  storage applications.\r\n\r\nTraditional kernel I/O stacks bring obvious overhead
  due to context switch, data copy, interrupt, resource synchronization and etc. SPDK
  minimizes the impact on CPU and Memory bus cycles during IO processing mainly by
  three ways. One is using the user-mode for storage applications rather than kernel
  mode. The devices that SPDK takes control are unbound from kernel space driver.
  And instead, UIO or VFIO driver is used for SPDK to operate devices directly from
  user space, which thereby eliminates costly kernel context switch. The second is
  that SPDK runs in a polled mode instead of interrupt mode. It polls devices for
  completions instead of waiting for interrupts, which reduces the related interrupt
  handling overhead. And the third one, the shared-nothing thread model. Separate
  queues exposed by a device like NVMe can be accessed without coordination. SPDK
  can send requests to the device from multiple threads of execution in parallel without
  locks for SPDK requires a hardware queue is only ever accessed from one thread at
  a time. \r\n\r\nBuilding upon such basis, SPDK further provides a full block stack
  as a user space library and provides NVMe-oF and vhost servers that are capable
  of serving disks over the network or to other processes. We can learn from these
  targets about how to implement a high performance storage target, or use them as
  the basis for production deployments. \r\n\r\nIn this session, we will walk through
  our practice about running SPDK NVMe-over-TCP on Arm servers. We will show the IO
  performance and multi-dimentional comparison with the linux kernel driver. And we
  will show our tuning and optimization details to get performance improved.\r\n\r\nThe
  session will have this outline:\r\n1.software framework and the key techniques of
  SPDK;\r\n2.pratice on SPDK NVMe-over-TCP to accelerate accessing remote NVMe devices
  on Arm servers;\r\n3.SPDK NVMe-over-TCP tuning and optimization on Arm servers. "
image: /assets/images/featured-images/lvc21/LVC21-208.png
session_id: LVC21-208
session_room: Track 1
session_slot:
  end_time: '10:40'
  start_time: '10:15'
session_speakers:
- speaker_bio: "Richael is software engineer from Arm. She has strong expertise in
    cloud storage technology, covering NVMe-oF, kernel, distribute storage system
    and solutions.\r\nRichael has rich experience in workloads profiling, tuning and
    optimization on Arm. As an active contributor to open source community, Richael
    is now focusing on SPDK and Ceph projects."
  speaker_company: Arm China, software engineer
  speaker_email: richael.zhuang@arm.com
  speaker_image: https://sessionize.com/image/7bbb-400o400o2-b3-8de7-48fe-9d0b-f60c59bd6b50.f0d16df8-226e-4077-b5bf-9f0a6aa8c1ea.jpg
  speaker_name: richael zhuang
  speaker_position: Arm
session_track: Data Center
tag: session
tags: Data Center
title: 'LVC21-208: Embracing High Performance Flash Storage with Arm'
---

Solid-state storage media is in the process of taking over the data center, whose growing advantages in performance bring a major challenge that current storage software stack overhead becomes a major bottleneck for developing high performance storage applications.

Traditional kernel I/O stacks bring obvious overhead due to context switch, data copy, interrupt, resource synchronization and etc. SPDK minimizes the impact on CPU and Memory bus cycles during IO processing mainly by three ways. One is using the user-mode for storage applications rather than kernel mode. The devices that SPDK takes control are unbound from kernel space driver. And instead, UIO or VFIO driver is used for SPDK to operate devices directly from user space, which thereby eliminates costly kernel context switch. The second is that SPDK runs in a polled mode instead of interrupt mode. It polls devices for completions instead of waiting for interrupts, which reduces the related interrupt handling overhead. And the third one, the shared-nothing thread model. Separate queues exposed by a device like NVMe can be accessed without coordination. SPDK can send requests to the device from multiple threads of execution in parallel without locks for SPDK requires a hardware queue is only ever accessed from one thread at a time. 

Building upon such basis, SPDK further provides a full block stack as a user space library and provides NVMe-oF and vhost servers that are capable of serving disks over the network or to other processes. We can learn from these targets about how to implement a high performance storage target, or use them as the basis for production deployments. 

In this session, we will walk through our practice about running SPDK NVMe-over-TCP on Arm servers. We will show the IO performance and multi-dimentional comparison with the linux kernel driver. And we will show our tuning and optimization details to get performance improved.

The session will have this outline:
1.software framework and the key techniques of SPDK;
2.pratice on SPDK NVMe-over-TCP to accelerate accessing remote NVMe devices on Arm servers;
3.SPDK NVMe-over-TCP tuning and optimization on Arm servers.