---
categories:
- bud20
description: Autonomous vehicles are becoming a part of normal life as companies,
  universities and foundations are heavily investing in projects to aid its research
  and development. One such initiative that has taken up wide acceptance by the automotive
  community is Autoware Foundation. This project supports self-driving mobility and
  has been adopted by over 100 companies and 40 vehicles. 96Boards, Autoware Foundation
  and its members (Xilinx, AutoCore) have teamed up to design an Autonomous driving
  solution using a customized Ultra96 Board and the Autoware stack. Using a distributed
  system design we will demonstrate some of the key autonomous driving features, which
  will also have the potential to be deployed as an ADAS module.<br><br>The talk will
  describe in detail the design and implementation of the vision perception unit of
  RoboCar covering the hardware, software features and performance capabilities. The
  vision perception unit performs the main perception tasks in autonomous driving
  including object detection, traffic light detection and self-parking. The algorithms
  and models are open source and have been implemented using Xilinx FPGAs on the Ultra96
  boards. The design of the functional nodes in the autonomous vehicle is distributed
  in nature with the nodes talking to each other over a Distributed Data Service layer
  as a messaging middleware and a real-time kernel to coordinate the actions. We also
  demonstrate the capability of Ultra96 MPSoC technology to handle multiple channels
  of LVDS real time camera and the integration with the Lidar/Radar point cloud fusion
  to feed into the decision making unit of the overall system.<br><br>The presentation
  will also cover the Autoware localization algorithms like NDT and AI object detection
  models like Yolov3. The details of image capture and algorithm processing of the
  vision perception pipeline will be presented along with the performance measurements
  in each phase of the pipeline. We will also be demonstrating the ability to update
  the processing unit capability through OTA. It is envisioned that the core AI engine
  will require regular updates with the latest training values; hence a built-in platform
  level mechanism supporting such capability is essential for real world deployment.
image:
  featured: 'true'
  path: https://static.linaro.org/connect/bud20/images/BUD20-100K2.png
session_id: BUD20-100K2
session_speakers:
- speaker_bio: Director 96Boards, Board of Director Autoware Foundation
  speaker_company: Linaro
  speaker_image: http://avatars.sched.co/4/6e/7349692/avatar.jpg.320x320px.jpg?baf
  speaker_name: Yang Zhang
  speaker_position: Director 96Boards, Board of Director Autoware Foundation
  speaker_role: speaker
- speaker_bio: Ravikumar Chakaravarthy is Sr. Director of Software at Xilinx Inc.
    He leads Open Source Software development at Xilinx including but not limited
    to Linux kernel, UBoot, OpenAMP, Xen, FreeRTOS, V4L, GStreamer, QEMU, Yocto, TVM/VTA
    etc. He is currently leading embedded software, AI/ML engines, virtualization,
    co-simulation, VCU and multimedia software, RFSoC, safety, security, platform
    management and driver development for Xilinxâ€™s next generation MPSoC platforms.
    During two decades in the industry he has lead many projects in Embedded space
    spanning Data Centers, Storage, Aerospace and Defense, Wireless, Automotive, Multimedia
    and Imaging solutions.
  speaker_company: Xilinx
  speaker_image: http://avatars.sched.co/6/a8/10526819/avatar.jpg.320x320px.jpg?6ec
  speaker_name: Ravikumar Chakaravarthy
  speaker_position: Sr. Director Software
  speaker_role: speaker
session_track: Automotive
tag: session
tags: Automotive
title: 'BUD20-100K2 - BUD20-100K2 Keynote: RoboCar Vision Perception Unit: Using Ultra96
  Board and Autoware Stack'
---