---
categories:
- bkk19
description: Inference engines come in various forms and sizes which has a direct
  effect on their capabilities and memory footprint. During this presentation, we
  will look at different engine architectures and the memory trade-off implied by
  their target run-time environment, and some dissecting of ArmNN to put things in
  perspective with actual numbers.
image:
  featured: 'true'
  path: /assets/images/featured-images/bkk19/BKK19-204.png
session_attendee_num: '20'
session_id: BKK19-204
session_room: Session Room 1 (Lotus 1-2)
session_slot:
  end_time: '2019-04-02 08:55:00'
  start_time: '2019-04-02 08:30:00'
session_speakers:
- speaker_bio: ''
  speaker_company: Linaro
  speaker_image: /assets/images/speakers/placeholder.jpg
  speaker_location: ''
  speaker_name: Nicolas Pitre
  speaker_position: Software Architect
  speaker_username: nicolas.pitre
- speaker_bio: <br>TBD
  speaker_company: ''
  speaker_image: /assets/images/speakers/bkk19/nicolas-pitre.jpg
  speaker_location: ''
  speaker_name: Nicolas Pitre
  speaker_position: Linaro OCTO
  speaker_username: nicolas_pitre.748u1sx
session_track: Machine Learning/AI
tag: session
tags:
- Machine Learning/AI
title: AI Inference -- Smart vs Small
---